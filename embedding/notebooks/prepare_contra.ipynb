{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tiger/miniconda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import gc\n",
    "import datasets\n",
    "import json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from safetensors.torch import load_file, save_file, safe_open\n",
    "from src import Data, Metrics, ModelArgs, get_model_and_tokenizer\n",
    "\n",
    "args = ModelArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 60/60 [00:00<00:00, 274436.47files/s]\n",
      "Generating train split: 1290334 examples [00:14, 86871.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# v2 training/testing (save oracle ctr and search_id)\n",
    "\n",
    "def process_fn(data):\n",
    "    outputs = {\"query\": [], \"pos\": [], \"neg\": [], \"pos_real_ctrs\": [], \"pos_oracle_ctrs\": [], \"neg_real_ctrs\": [], \"neg_oracle_ctrs\": [], \"search_id\": [], \"pos_ids\": [], \"neg_ids\": []}\n",
    "    for query, doc, search_result_click_cnt, real_ctr, oracle_ctr, search_id, doc_id in zip(data[\"query\"], data[\"doc_info\"], data[\"search_result_click_cnt\"], data[\"real_clk_ctr\"], data[\"video_oracle_ctr\"], data[\"search_id\"], data[\"doc_id\"]):\n",
    "        if doc is None:\n",
    "            continue\n",
    "\n",
    "        doc = json.loads(doc)\n",
    "        real_ctr = float(real_ctr)\n",
    "        oracle_ctr = float(oracle_ctr)\n",
    "\n",
    "        doc_text = \"\"\n",
    "\n",
    "        fields = [\n",
    "            (\"title\", doc.get('title', '').strip()),\n",
    "            (\"username\", doc.get('username', '').strip()),\n",
    "            (\"music\", doc.get('music', '').strip()),\n",
    "            (\"poi\", doc.get('poi', '').strip()),\n",
    "            (\"challenge\", doc.get('challenge', '').strip()),\n",
    "            (\"ocr\", doc.get('ocr', '').strip()),\n",
    "            (\"asr\", doc.get('asr', '').strip())\n",
    "        ]\n",
    "\n",
    "        for field_name, field_value in fields:\n",
    "            doc_text += f\"<{field_name}>{field_value}\\n\\n\"\n",
    "\n",
    "        outputs[\"query\"].append(query)\n",
    "        outputs[\"search_id\"].append(search_id)\n",
    "        if search_result_click_cnt > 0:\n",
    "            outputs[\"pos\"].append([doc_text])\n",
    "            outputs[\"neg\"].append([\"NAN\"])\n",
    "            outputs[\"pos_real_ctrs\"].append([real_ctr])\n",
    "            outputs[\"pos_oracle_ctrs\"].append([oracle_ctr])\n",
    "            outputs[\"pos_id\"].append([doc_id])\n",
    "            outputs[\"neg_real_ctrs\"].append(None)\n",
    "            outputs[\"neg_oracle_ctrs\"].append(None)\n",
    "        else:\n",
    "            outputs[\"pos\"].append([\"NAN\"])\n",
    "            outputs[\"neg\"].append([doc_text])\n",
    "            outputs[\"pos_real_ctrs\"].append(None)\n",
    "            outputs[\"pos_oracle_ctrs\"].append(None)\n",
    "            outputs[\"neg_real_ctrs\"].append([real_ctr])\n",
    "            outputs[\"neg_oracle_ctrs\"].append([oracle_ctr])\n",
    "\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Fuck query {query} search_cnt {search_result_click_cnt}\")\n",
    "\n",
    "\n",
    "    return outputs\n",
    "\n",
    "base_dir = \"/mnt/bn/search-douyin-rank-yg/all_data_from_lf/text_embedding_data/query_doc_info_sample_order_1102_eval_v1\"\n",
    "# base_dir = \"/mnt/bn/search-douyin-rank-yg/all_data_from_lf/text_embedding_data/query_doc_info_sample_order_1102_eval_v2\"\n",
    "# base_dir = \"/mnt/bn/search-douyin-rank-yg/all_data_from_lf/text_embedding_data/query_doc_info_sample_order_1102_eval_v3\"\n",
    "dataset = datasets.load_dataset(\"parquet\", data_files=glob(f\"{base_dir}/*.parquet\"), split=\"train\")\n",
    "# contra_dataset = dataset.map(process_fn, num_proc=32, batched=True, remove_columns=dataset.column_names, batch_size=100)\n",
    "# contra_dataset.save_to_disk(f\"{base_dir}_peitian\")"
   ]
  }
 ],
 "metadata": {
  "fileId": "8b4ec59d-5efd-4554-b3e4-0e8240e1f283",
  "filePath": "/opt/tiger/DouyinSearchEmb-Peitian/notebooks/data.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
